{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhcNbTVMP5pAq9JfdnOxKW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikolay1982Nikolaev/Bayes-Bicocca/blob/main/L_5_and_6_7_processo_stocastico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I metodi MCMC utilizzano le proprieta della catene di Markov per generare delle realizzazioni da variabili casuali anche di ampie dimensioni e ricavare per via simulativa i momenti dalla distribuzione a posteriori\n",
        "\n",
        "L'utilizzo dei metodi basati sulle simulazioni della distribuzione a posteriori e' praticabile generando delle realizzazioni pseudo casuali di valori della parametro dalla distibuzione a posteriori\n",
        "\n",
        "Le realizzazioni si considerano come approssimazioni di valori indipendenti e somiglianti dalla distribuzione a posteriori del modello\n",
        "\n",
        "I metodi MC approssimano i moemnti della distribuzione del parametro tramite calocli numerici.\n",
        "\n",
        "SIa $\\theta$ parametro di interese e $\\y_1...y_n$ il vettore dei valori numerici campionari dalla distribuzione $p(y_1...y_n|\\theta)$\n",
        "\n",
        "Se si campiona dalla distribuzioen a posteriori $p(\\theta|y_1...y_n)$ si ottine un insieme di valori $$\\theta^1...\\theta^S \\sim IID \\sim p(\\theta|y_1...y_n)$$\n",
        "\n",
        "La distribuzione empirica di questi campioni $\\theta^1....\\theta^S$ approssima la distribuzione a posteriori\n",
        "\n",
        "Tale distribuzione empirica e' approssimazione MC di $p(\\theta|y_1...y_n)$\n",
        "\n",
        "La distribuzione empirica dei campioni MC fornisceun'approssimazione sempre piu vicina alla densita reale man mano che S diventa piu grande\n",
        "\n",
        "SIa $h(\\theta)$ una generica funzione per la forte legge dei grandi numeri\n",
        "\n",
        "$$\\frac{1}{S} \\sum_{2=1}^S h(\\theta^S)-> E[h(\\theta)|y_1...y_n]= \\int_{\\Theta}h(\\theta)p(\\theta|y_1...y_n)d\\theta$$ quando $S->\\infty$\n",
        "\n",
        "$$\\bar{\\theta}= \\sum_{x=1}^S h(\\theta^S)-> E[\\theta|y_1...y_n]$$\n",
        "\n",
        "$$\\sum_{s=1}^S$ \\frac{\\theta^S - \\bar{\\theta}}{S-1} -> Var[\\theta|y_1...y_n]$\n",
        "\n",
        "la distribuzuoone empirica di $[\\theta^1...\\theta^S]-> p(\\theta|y_1...y_n)$\n",
        "\n",
        "Lo stimatore MC ha la proprieta di correttezza e di consistenza\n",
        "\n",
        "Per definire l'accuratezza occore calcolare\n",
        "\n",
        "$$\\bar{\\theta}= \\sum_{2=1}^S \\frac{\\theta^S}{S}$$\n",
        "la media campionaria dei campioni MC\n",
        "\n",
        "\n",
        "Per il teorema centrale del limite la media campionaria segue una distribuzione normale con:\n",
        "$$E[\\theta|y_1...y_n]$$ e ds= $\\sqrt{Var[\\theta|y_1..y_n]/S}$"
      ],
      "metadata": {
        "id": "t2mTttBxlh5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'errore standard MC e' un'approssimazione della precedente deviazione standard\n",
        "$$\\hat{\\sigma}^2 = \\sum_{s=1}^S (\\theta^S - \\bar{\\theta})/(S_1)$$\n",
        "\n",
        "La stime MC della $Var[\\theta|y_1...y_1]$ ;'errore standard e'\n",
        "$$\\frac{\\hat{\\sigma^2}}{S}$$\n",
        "\n",
        "La pratica standard consiste nello scegliere S sufficiente grande in modo che l'errore standard di MC sia piccolo\n",
        "\n"
      ],
      "metadata": {
        "id": "Fzt4DGSPlh73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Catene di Markov\n",
        "\n",
        "SI considera una sequenza di var.caas indicizzzate rispetto ad instanti temporali $Y^{(1)}....Y^{(t)}$ con t=1...T che indica l'instante\n",
        "\n",
        "Nel seguito questa seq raccolta nel vettore $Y^{(T)}$ definice processo stocastico con la seguente proprieta:\n",
        "\n",
        "$$P(Y^{(t)}|Y^{(t-1)}, ...Y^{(1)})= P(Y^{(t)}|Y^{(t-1)})$$\n",
        "ogni $t\\geq 1$\n",
        "\n",
        "In generale ci si riferisce al vettore $Y^{(t)}$ come un processo definito da una sequenza di stati che iniziano con $Y^{(1)}$\n",
        "\n",
        "Lo spazio degli stati del processo e' linsieme dei valori che il processo assume\n",
        "\n",
        "Qundo ci riferiam al parametro d'interesse i valori che definiscono lo spazio del parametro caratterizzano lo spazio degli stati.\n",
        "\n"
      ],
      "metadata": {
        "id": "oBk1pq9Dlh-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Catena OMOGENEo rispetto al tempo quando la distribuzione condizionata $P(Y^{(t+1)}|Y^{(t)})$ non dipende da t si puo scrivere\n",
        "\n",
        "$$P(Y^{(t+1)}|Y^{(t)})= P(Y^{(2)}|Y^{(1)})$$\n",
        "- per $t \\geq 1$\n",
        "\n",
        ". In pratica la probabilita di un evento future t+1 dato che si conosce la storia del processo fino ad oggi dipende solo dallo stato attuale della catena\n",
        "\n",
        "Ogni componente e' definito dallo stato del processo. La probabilita relativa ad una coppia di stati si indica:\n",
        "$$P_{j|k}= P(Y^{(t)}= j|Y^{(t-1)}= k)$$\n",
        "\n",
        "definisce la rpobabilita di transizione nel periodo t allo stato j dato che nel periodo (t-1) il processo si trovva nello stato k\n",
        "\n",
        "La matrice in cui sono raccolte queste probabilita per ogni stato del processo e' detta matrice di transizione e le rispettive probabilita definiscono gli spostamenti tra stati del process ad istanti successivi.\n",
        "\n",
        "La probabilita definiscono il kernel di transizione della catena di Markov: prob.di effettura una transizione verso un certo stato (j nell'esempio) qundo ci si trova un altro stao (k)\n",
        "\n",
        "Pertanto costituisce la regola sottostante i passaggi tra stati della catena, infatti l'andamento del processo nel tempo si determina in accordo alle proabilita iniziale di ogni stato e di transizione tra stati\n",
        "\n",
        "Tutte queste probabilita si racolgono nella matrice della prob.di transizione o - $Î $. Questa e' una matrice quadrata le cui dimensioni sono definite dallo spazio degli stati con le seguente proprieta\n",
        "\n",
        "- tutte gli elementi sono non negativi $p_{j|k} \\geq 0$\n",
        "- la somma degli elementi di ogni riga e 1\n",
        "- la matrice e' definita positiva\n",
        "\n",
        "Il processo e' OMOGENEO rispetto al tempo quando le proabilita di transizione\n",
        "\n",
        "$$p_{j|k}= P(Y^{(t)}= k|Y^{(t-1)= j})$$\n",
        "\n",
        "noltre il processo si caratterizza per le probabilita di ogni stato al periodo iniziale detto prob inizlai delle catena che definiscono la distribuzione iniziale\n",
        "\n",
        "$$P(Y^{(1)}= k); P(Y^{(1)}= j)$$ e sono raclte nel vettore $\\pi$"
      ],
      "metadata": {
        "id": "pdLJ-StNliA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L7\n",
        "\n",
        "I processi stocastici che soddisfano la dipendenza condizonata alla variabile piu vicina temporalemente hanno la proprieta di Markov e costituiscono una catena di Markov\n",
        "\n",
        "La proprieta esprime il concetto che la conoscenza dello stato del processo nel momento attuale dipende dalle precedenti realizzazioni del processo soltanto attrraverso l'informazione fornita dalla conoscenza dello stato del processo nel periodo immediatamente precedente.\n",
        "\n",
        "Questa proprieta si puo esprimere anche dicendo che conoscere lo stato del processo ogi consente di prevedere lo stato domani in quanto questo non dipende da stati precedenti oltre a quello presente.\n",
        "\n",
        "La distribuzione congiunta delle variabili casuali determina le carateristiche delo processo stocastico\n",
        "\n",
        "In riferimento alle applicazioni a dati reali moti fenomeni si presentano come realizzazioni di questo processo aventi una struttura di dipendenza\n",
        "\n",
        "Stoto j- RICCORENTRE se partendo da j si ha una probabilita a 1 di ritornare a j in n passi\n",
        "\n",
        "TRANSIENTE se ce' una prob positiva di non tornare mai a j in n passi(la catena lascia j per sempre)\n",
        "\n",
        "PERIODO di uno stato e' il massimo numero di passi entro cui si ritorna allo stato\n",
        "\n",
        "STATO ASSORBENTE - della catena o stato chiuso quello stato s tale per cui $P(Y^t = s|Y^{t-1}= s)=1$\n",
        "si tratta di uno stto terminale entro il quale la catena e' BLOcata\n",
        "\n",
        "Una volta raggiunto stato non sono piu possibili altre transizioni\n",
        "\n",
        "Nella matrice di transizione sulla diagonale riferito alla riga corrispondente a questo stato e' uguale a 1\n",
        "\n",
        "La catena e' IRRIDUCIBILE se considerando una coppia di stati j,k e' possibile passare da j a k e viceversa in un numero dinito di passi, altrimenti la catena e' detta riducibile\n",
        "\n",
        "Se la catena e' irriducibile ogni stato e' ricorrente ed e' possibile visitarlo pi volte\n",
        "\n"
      ],
      "metadata": {
        "id": "HJ7huuoSliDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per un processo stocastico IRRIDUCIBILE e Apperiodico (omogeneo) esiste una distribuzione stazionaria o di equlibrio che rappresenta il comportamento asintotico del processo: le probabilita di ogni stato nel lungo periodo\n",
        "\n",
        "Si tratta della dstribuzione marginale del processo e si calocola risolvendo il sistema di equzioni di Chapman-Kolmogorov\n",
        "\n",
        "QUeste permettono di ricavare la matrice di transizione dopo n passi partendo da certe probabilita inziali per ciasuno stato\n",
        "\n",
        "Nelle equazioni la probabilita di passaggio da j a k in n+m passi si calcola considerando la somma dei prodotti delle probabilita di passaggioda k a i (i--uno stato intermedio) in n passi e delle probabilita di passaggio da i a j in m passi\n",
        "\n",
        "Il comortamento della catena al crescere dei passi determina la distribuzione di equlibrio che e' definita come limite del prodotto tra le probabilita inizlia $\\pi$ e di transsizione $\\Pi$ al crescere del numero di passi\n",
        "\n",
        "$$lim_{n0>\\infty}\\pi \\Pi^n$$\n",
        "\n",
        "Il valore di $\\pi$ tale che\n",
        "$$\\hat{\\pi}\\Pi= \\hat{\\pi}$$ e\n",
        "$$\\hat{\\pi}1'= 1$$\n",
        "definisce la distribuzione equlibrio (detta anche distribuzione invariate o steady -state distribution) del process\n",
        "\n",
        "La quota di tempo spesso in uno stato (perioro) si calocla partendo dalla distribuzione di equlibrio. Un famoso teorema dimostra che se la caena di Markov e' irrducibile allora ha un'unica distribuzione stazionario strettamente positiva\n",
        "\n",
        "Un teorema dimostra che se A e' una matrice stocastica irriducibile allora avra certamente un autovalore pari a 1 e tale autovalore e' il piu grande\n",
        "\n",
        "L\\autovettore associato a questo autovalore ha tutti valori positivi che corrispondono (a seguito di una normalizzazione) alla distribuzione stazionario del processo\n",
        "\n",
        "Pertanto la distribuzione di equlibrio si ricava anche prendento gli autovettori normalizzati corrispondenti al massimo autovalore\n",
        "\n"
      ],
      "metadata": {
        "id": "5uEoww-KliFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UDJ5IeDrliIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a_coXFezliKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PLWHsImKliNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XrOogYcOliQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iWEKd7xyliSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wxjsVUUsliVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W-0C9ZwpliXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PhSuZsKKliZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nwMqQfSOlicH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cV7Ho_pNliet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MYFdXwzOlihB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7sH35jPllijP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t5mF4RXDlilW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9GYeeKfOlinq"
      }
    }
  ]
}